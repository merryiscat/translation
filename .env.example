# API Configuration
LLM_API_KEY=your-api-key-here
LLM_API_ENDPOINT=https://your-api-endpoint.com/v1/chat/completions
LLM_MODEL_NAME=your-model-name

# Optional: Custom request body template (JSON format)
# If not set, will use OpenAI-compatible format
# Available variables: {model}, {system_prompt}, {user_content}, {temperature}
# Example:
# LLM_REQUEST_TEMPLATE={"model": "{model}", "messages": [{"role": "system", "content": "{system_prompt}"}, {"role": "user", "content": "{user_content}"}], "temperature": {temperature}}
